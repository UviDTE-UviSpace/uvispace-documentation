<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>General overview &#8212; UviSpace 1.0.0 documentation</title>
    
    <link rel="stylesheet" href="_static/haiku.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="top" title="UviSpace 1.0.0 documentation" href="index.html" />
    <link rel="next" title="Getting Started" href="Starting.html" />
    <link rel="prev" title="UviSpace" href="index.html" /> 
  </head>
  <body role="document">
      <div class="header" role="banner"><h1 class="heading"><a href="index.html">
          <span>UviSpace 1.0.0 documentation</span></a></h1>
        <h2 class="heading"><span>General overview</span></h2>
      </div>
      <div class="topnav" role="navigation" aria-label="top navigation">
      
        <p>
        «&#160;&#160;<a href="index.html">UviSpace</a>
        &#160;&#160;::&#160;&#160;
        <a class="uplink" href="index.html">Contents</a>
        &#160;&#160;::&#160;&#160;
        <a href="Starting.html">Getting Started</a>&#160;&#160;»
        </p>

      </div>
      <div class="content">
        
        
  <a class="reference internal image-reference" href="_images/portada.jpg"><img alt="_images/portada.jpg" class="align-center" src="_images/portada.jpg" style="width: 1100px;" /></a>
<div class="section" id="general-overview">
<h1>General  overview<a class="headerlink" href="#general-overview" title="Permalink to this headline">¶</a></h1>
<p>The project is aimed to control an indoor intelligent space where several unmanned vehicles are simultaneously observed and controlled through a distributed vision system, a central controller and an Arduino board embedded at each vehicle. The physical system was set up in the university in order to run tests and try new algorithms and solutions.</p>
<p>Hence, the whole system can be divided into three different elements:</p>
<ul>
<li><p class="first">The <em>data fussion controller</em>, which consists in a CPU that controls the whole system. The <em>uvispace</em> software project is executed there, whose main tasks are:</p>
<blockquote>
<div><ul class="simple">
<li>communicate with the FPGA-based image processing nodes, using the TCP/IP protocol</li>
<li>Merge the data obtained from the image processing nodes</li>
<li>Get the global coordinates of the UGVs</li>
<li>Given the destination of the UGVs, calculate the optimal path</li>
<li>Calculate the UGVs speed, using a navigation model</li>
<li>Communicate with the Arduino controllers, using the ZigBee protocol, and send them the speed set points.</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">The 4 <em>image processing nodes</em>. Their main component is an FPGA, with a camera peripheral. Each camera frame is processed in the FPGA, and the obtained results are sent to the <em>data fussion controller</em> through an Ethernet port.</p>
</li>
<li><p class="first">The Arduino controllers, that control each UGV&#8217;s sensors and actuators. They receive orders from the <em>data fussion controller</em> through the data received from the serial port, connected to a XBee transceiver.</p>
</li>
</ul>
<p>The main structure of the system can be observed in the diagram below.</p>
<img alt="_images/general_diagram.png" class="align-center" src="_images/general_diagram.png" />
</div>
<div class="section" id="software-project">
<h1>Software project<a class="headerlink" href="#software-project" title="Permalink to this headline">¶</a></h1>
<p>The software subproject inside the UviSpace project is called uvispace as well. It is a <strong>Python2.7</strong> project, and it is structured into 2 main packages, namely <em>uvirobot</em> and <em>uvisensor</em>.</p>
<p>The <em>uvirobot</em> package deals with the classes and functions needed to
implement the algorithms for moving an UGV and communicating with it,
while the <em>uvisensor</em> package is used to communicate with FPGA devices using a
TCP/IP connection and receive scene information captured through camera
peripherals.</p>
<div class="section" id="uvirobot">
<h2>uvirobot<a class="headerlink" href="#uvirobot" title="Permalink to this headline">¶</a></h2>
<p>The <em>uvirobot</em> package consist in 2 callable scripts:</p>
<ul class="simple">
<li><strong>messenger.py</strong> stablishes the communication to the specified UGV, using the ZigBee protocol. Thus, prior runnning it an XBee module has to be connected to the PC, and another one to the Arduino board serial port, and both configured accordingly. Once the communication is stablished, the module <em>listens</em> to speed set points and send them to the UGV. When the execution is cancelled, a plot with the delay times is obtained and then the program ends.</li>
<li><strong>controller.py</strong> <em>listens</em> to input UGV position values and destination coordinates, calculates the UGV optimal path, and finally outputs the speed set points needed to achieve the planned path.</li>
</ul>
<p>Moreover, there are 5 importable libraries inside the <em>uvirobot</em> package:</p>
<ul class="simple">
<li><strong>path_tracker.py</strong> contains a class whose methods calculate an UGV&#8217;s path points, once given a position and destination, and then stores them in an attribute.</li>
<li><strong>plotter.py</strong> contains functions used to construct a graph with a predefined format. It is designed to map the calculated vs. real path of an UGV, and the delay times.</li>
<li><strong>robot.py</strong> contains the <em>RobotController()</em> class, where each instantiated object represents an UGV, and stablishes the upper interface for working with its speed values.</li>
<li><strong>serialcomm.py</strong> contains the <em>SerMesProtocol()</em> class, which is a child of the built-in python <em>pyserial</em> class. It defines a serial protocol, which will be used by the XBee modules for communicating the CPU with an UGV.</li>
<li><strong>speedtransform.py</strong> contains the <em>Speed()</em> class, for dealing with operations related to the speed values, such as transform between different scales or ensuring that the values are between valid boundaries.</li>
</ul>
<p>Finally, the package contains an auxiliary module into the <em>resources</em> folder, called <em>teleoperation.py</em>. This is a callable module that allows to control the UGV with the keyboard, which is specially useful when the <em>uvispace</em> package has to be tested.</p>
</div>
<div class="section" id="uvisensor">
<h2>uvisensor<a class="headerlink" href="#uvisensor" title="Permalink to this headline">¶</a></h2>
<p>The <em>uvisensor</em> contains 1 callable module, <strong>multiplecamera.py</strong>. It is based on multithreading. The purpose of this module is to manage the information of N cameras, merge the vertices of every tracker and obtain the final number of UGVs(triangles) with their pose. There is a shared variable with all the vertices obtained from each camera.</p>
<p>The connection via TCP/IP to the cameras, as well as the processing of the images from each camera, is achieved in parallel.</p>
<p>Finally, another thread communicates with the user in order to get commands. At the moment, the only command is &#8216;Quit Program&#8217; (&#8216;Q&#8217;), but this functionality can be easily increased in the future.</p>
<p>Summing up, the list of threads is:</p>
<ul class="simple">
<li>1 main thread that will merge the information from every camera (VideoSensor).</li>
<li>N threads for getting data from the N cameras connected to the system.</li>
<li>1 user oriented thread for getting commands from the user.</li>
</ul>
<p>The package has, as well, 4 importable modules:</p>
<ul class="simple">
<li><strong>client.py</strong> contains the <em>Client()</em> class, which is a child of the <em>Socket</em> class from the <em>socket.socket</em> built-in Python module. This class contains methods for communicating specifically with the design FPGA hardware. Its methods allow to open and close the connection correctly, and to write and read from valid registers with the right format.</li>
<li><strong>geometry.py</strong> contains 2 classes. The <em>Triangle()</em> class is used for performing geometrical operations inherent to isosceles triangles, in order to get its base length, barycenter, position, angle... The <em>Segment()</em> class is used to determine a segment from its 2 points, and calculate afterwards the distance to another point.</li>
<li><strong>imgprocessing.py</strong> contains the <em>Image()</em> class, which has image-oriented methods, based on matrix operations, for getting useful information from image data.</li>
<li><strong>videosensor.py</strong> has the <em>VideoSensor()</em> class and several functions related to it. Each instantiated object represent an external FPGA device. Thus, this class has methods for setting up the TCP/IP connection, configuring the FPGA registers, and interact with it.</li>
</ul>
<a class="reference internal image-reference" href="_images/software_diagram.png"><img alt="_images/software_diagram.png" class="align-center" src="_images/software_diagram.png" style="width: 750px;" /></a>
</div>
</div>
<div class="section" id="hardware-design-project">
<h1>Hardware design project<a class="headerlink" href="#hardware-design-project" title="Permalink to this headline">¶</a></h1>
</div>
<div class="section" id="arduino-controllers-project">
<h1>Arduino controllers project<a class="headerlink" href="#arduino-controllers-project" title="Permalink to this headline">¶</a></h1>
</div>
<div class="section" id="about-us">
<h1>About us<a class="headerlink" href="#about-us" title="Permalink to this headline">¶</a></h1>
<p>The project was developed by a team of researchers at the <em>Electronic Technology Department</em> in the <strong>University of Vigo</strong></p>
</div>


      </div>
      <div class="bottomnav" role="navigation" aria-label="bottom navigation">
      
        <p>
        «&#160;&#160;<a href="index.html">UviSpace</a>
        &#160;&#160;::&#160;&#160;
        <a class="uplink" href="index.html">Contents</a>
        &#160;&#160;::&#160;&#160;
        <a href="Starting.html">Getting Started</a>&#160;&#160;»
        </p>

      </div>

    <div class="footer" role="contentinfo">
        &#169; Copyright 2016, Javier López-Randulfe.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.4.8.
    </div>
  </body>
</html>